{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用各種不同方式寫同樣的神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始準備\n",
    "\n",
    "Keras 可以用各種不同的深度學習套件當底層, 我們在此指定用 Tensorflow 以確保執行的一致性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd #其實不會用到\n",
    "\n",
    "from ipywidgets import interact, IntSlider, Button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀入建構神經網路用到的 Keras 相關函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras functions\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Keras dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Keras utils\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀入 MNIST 數據庫\n",
    "\n",
    "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的[原始網頁](http://yann.lecun.com/exdb/mnist/)。\n",
    "\n",
    "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 由 Keras 讀入 MNIST\n",
    "標準手段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "養成好習慣，沒事就看看資料的長相"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 training data with size 28 x 28\n",
      "There are 10000 testing  data with size 28 x 28\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d training data with size %d x %d\" %x_train0.shape)\n",
    "print(\"There are %d testing  data with size %d x %d\" %x_test0.shape)\n",
    "\n",
    "# print(\"共 %d 訓練資料，每筆資料的大小為 %d x %d\" %x_train.shape)\n",
    "# print(\"共 %d 測試資料，每筆資料的大小為 %d x %d\" %x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 輸入格式整理\n",
    "\n",
    "我們現在要用標準神經網路學學手寫辨識。原來的每筆數據是個 28x28 的矩陣 (array), 但標準神經網路只吃「平平的」, 也就是每次要 28x28=784 長的向量。因此我們要用 `reshape` 調校一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train0.reshape(60000, 784)\n",
    "x_test = x_test0.reshape(10000, 784)\n",
    "\n",
    "# x_train = x_train0.reshape(60000, 28*28)\n",
    "# x_test = x_test0.reshape(10000, 28*28)\n",
    "\n",
    "# x_train = x_train0.reshape(60000, -1)\n",
    "# x_test = x_test0.reshape(10000, -1)\n",
    "\n",
    "# x_train = x_train0.reshape(x_train0.shape[0], x_train0.shape[1]*x_train0.shape[2])\n",
    "# x_test = x_test0.reshape(x_test0.shape[0], x_test0.shape[1]*x_test0.shape[2])\n",
    "\n",
    "# x_train = x_train0.reshape(x_train0.shape[0], np.prod(x_train0.shape[1:]))\n",
    "# x_test = x_test0.reshape(x_test0.shape[0], np.prod(x_test0.shape[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將資料線性單位化至 $[0, 1]$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TA forgot to normalize y_train , so you can fix it .\n",
    "x_train -= x_train.min()\n",
    "x_train = x_train/x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min(), x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train0, 10)\n",
    "y_test = np_utils.to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來準備另一個 label，將 0~9 分成偶數(y=0)、奇數 (y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train01 = np.ones_like(y_train0)# these is useless here , just want to show you , you can use these function to do something\n",
    "y_train01[y_train0%2==0] = 0\n",
    "\n",
    "y_test01 = np.ones_like(y_test0)\n",
    "y_test01[y_test01%2==0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "沒事用互動模式畫個圖，十分酷炫 (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNumber(idx):\n",
    "    plt.imshow(x_train0[idx], 'Greys')\n",
    "    plt.title(\"Number: %d\\n Evev/odd label: %d\" %(y_train0[idx], y_train01[idx]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c0ef4164784e97894fbfeb258d428e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Data Index', max=59999), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotNumber(idx)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plotNumber, \n",
    "         idx=IntSlider(value=0, description='Data Index', min=0, max=x_train0.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train01 = np_utils.to_categorical(y_train01, 2)\n",
    "y_test01 = np_utils.to_categorical(y_test01, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 回顧 Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第一周的時候，我們以下列的方式建立了一個具有下列設定\n",
    "\n",
    "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
    "* 每個 hidden layer 用 <span style=\"color:red;\">500</span> 個神經用\n",
    "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span> (雖然好像有些同學測試出 <span style=\"color:red;\"> ReLU </span> 比較好用...)\n",
    "* 最後一層為類別層，有 **10** 個神經元，Activation Function 為 ``softmax``。\n",
    "\n",
    "的神經網路，建立指令是透過建立 `Sequential()` 和 `.add` 的方式逐層建立，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立空的神經網路學習機\n",
    "model = Sequential()\n",
    "\n",
    "# 逐層建立神經網路\n",
    "model.add(Dense(500, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 另一種使用 Sequential 建立神經網路的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "觀察 ''model.layers``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x1f1da628668>,\n",
       " <keras.layers.core.Activation at 0x1f1da640978>,\n",
       " <keras.layers.core.Dense at 0x1f1da658828>,\n",
       " <keras.layers.core.Activation at 0x1f1da658160>,\n",
       " <keras.layers.core.Dense at 0x1f1da6726d8>,\n",
       " <keras.layers.core.Activation at 0x1f1da6724a8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers # list all component in the neurnal network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現 `model` 就是一堆神經網路***層*** 堆疊起來。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Python\n",
    "# 建立空的神經網路學習機\n",
    "model = Sequential()\n",
    "\n",
    "# 逐層建立神經網路 \n",
    "model.add(Dense(500, input_dim=784)) # 將 `<keras.layers.core.Activation at 0xe558ef0>` 加進 model.layers\n",
    "model.add(Activation('sigmoid'))     # 將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
    "model.add(Dense(500))                # 將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
    "model.add(Activation('sigmoid'))     # 將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
    "model.add(Dense(10))                 # 將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
    "model.add(Activation('softmax'))     # 將 `<keras.layers.core.Activation at 0xe58a898>` 加入 model.layers\n",
    "\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "換言之，神經網路其實就是將隱藏層逐層堆疊在一起的 list，因此，我們也可以 list 的形式來建立相同的神經網路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們將兩個隱藏層及其 Activation Function 分別寫在 list 中，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer = [Dense(500, input_dim=784), \n",
    "               Activation('sigmoid')]\n",
    "\n",
    "second_layer = [Dense(500), \n",
    "                Activation('sigmoid')]\n",
    "\n",
    "output_layer = [Dense(10), \n",
    "                Activation('softmax')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從基本的 Python 資料結構中，我們知道 list 可以用 `+` 來進行合併，所以我們先來看看這三個 list 合併後的樣子。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x1f1da5c0588>,\n",
       " <keras.layers.core.Activation at 0x1f1d94f76a0>,\n",
       " <keras.layers.core.Dense at 0x1f1da5c0ac8>,\n",
       " <keras.layers.core.Activation at 0x1f1da5ce898>,\n",
       " <keras.layers.core.Dense at 0x1f1b7eb5a90>,\n",
       " <keras.layers.core.Activation at 0x1f1da68cb70>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer + second_layer + output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合併起來的 list 看起來就像是某個 `model.layers` 一樣，因此，我們只需將這些寫成 list 的隱藏層 `+` 起來送進 `Sequential` 中即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(first_layer + second_layer + output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: 用 `.add` 和用 list 寫法建立的神經網路之差異？\n",
    "\n",
    "### A: 沒有任何差別，前者可以很直覺得將神經網路堆疊起來，但後者則是轉移學習 (Transfer Learning) 的方式之一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 站在巨人的肩膀上 - 轉移學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "舉例來說，如果我們今天想進行的辨識資料從辨識數字 (0~9) 變成了辨識奇偶數 (0 or 1)，而且我們希望延用之前***除了最後一層***的模型。\n",
    "\n",
    "顯然地，目前神經網路的 output 就與我們的需求不同，但我們想把前兩個隱藏層原封不動，只定義***新的最後一層***。(output 從10個變成2個)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_except_last = [Dense(500, input_dim=784), \n",
    "                   Activation('sigmoid'),\n",
    "                   Dense(500), \n",
    "                   Activation('sigmoid')]\n",
    "\n",
    "output_layer = [Dense(10), \n",
    "                Activation('softmax')]\n",
    "\n",
    "model_num = Sequential(all_except_last + output_layer)\n",
    "model_num.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取個權重，記得要先 ``compile``，才能 ``fit``, ``evaluate``, ``predict``, ``predict_classes``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "舉例來說，如果我們今天想進行的辨識資料從辨識數字 (0~9) 變成了辨識奇偶數 (0 or 1)，而且我們希望延用之前***除了最後一層***的模型。\n",
    "\n",
    "顯然地，目前神經網路的 output 就與我們的需求不同，但我們想把前兩個隱藏層原封不動，只定義***新的最後一層***。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num.load_weights('handwriting_model_weights.h5')\n",
    "model_num.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 38us/step\n",
      "Loss: 0.470515\n",
      "準確率: 86.226667\n"
     ]
    }
   ],
   "source": [
    "score = model_num.evaluate(x_train, y_train, batch_size=1000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "但這個網路並不是重點，我們只希望***借用***某些部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們希望**借用**這個模型的某些部分。來建立 **奇、偶數辨識模型**，模型設定如下：\n",
    "\n",
    "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
    "* 每個 hidden layer 用 <span style=\"color:red;\">500</span> 個神經元\n",
    "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span> (雖然好像有些同學測試出 <span style=\"color:red;\"> ReLU </span> 比較好用...)\n",
    "* 最後一層為類別層，有 ~~10~~ **<span style=\"color:red;\">2</span>** 個神經元，Activation Function 為 ``softmax``。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_except_last = [Dense(500, input_dim=784), \n",
    "                   Activation('sigmoid'),\n",
    "                   Dense(500), \n",
    "                   Activation('sigmoid')]\n",
    "\n",
    "output_layer = [Dense(10), \n",
    "                Activation('softmax')]\n",
    "\n",
    "model_num = Sequential(all_except_last + output_layer)\n",
    "model_num.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 644,002\n",
      "Trainable params: 644,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 因為上面已經定義了除了最後一層的所有layer，就是我們希望延用的部分，所以這部分不用重新宣告\n",
    "# all_except_last = [Dense(500, input_dim=784), \n",
    "#                    Activation('sigmoid'),\n",
    "#                    Dense(500), \n",
    "#                    Activation('sigmoid')]\n",
    "\n",
    "new_output_layer = [Dense(2, activation='softmax')]\n",
    "\n",
    "model_eo = Sequential(all_except_last + new_output_layer)\n",
    "model_eo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什麼都不做，就直接 ``evaluate``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 26us/step\n",
      "Loss: 0.693672\n",
      "準確率: 49.153333\n"
     ]
    }
   ],
   "source": [
    "model_eo.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "score = model_eo.evaluate(x_train, y_train01, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 1.5696 - acc: 0.4980\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.6712 - acc: 0.5808\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.6437 - acc: 0.6064\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.5888 - acc: 0.6386\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.4668 - acc: 0.7788\n"
     ]
    }
   ],
   "source": [
    "training_history = model_eo.fit(x_train, y_train01, batch_size=1000, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練過後再看一次："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 24us/step\n",
      "Loss: 0.408339\n",
      "準確率: 81.956666\n"
     ]
    }
   ],
   "source": [
    "score = model_eo.evaluate(x_train, y_train01, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們再回頭看看原本模型發生什麼事情 =>因為舊模型的一些layer被新模型借走去train，那些layer都是同一份copy，所以舊模型的權重就也被改變。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 30us/step\n",
      "Loss: 2.428415\n",
      "準確率: 9.751667\n"
     ]
    }
   ],
   "source": [
    "model_num.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "score = model_num.evaluate(x_train, y_train, batch_size=1000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果希望借來的模型權重，在訓練過程中不要改變，該如何做？ => 宣告每個layer的trainable成false，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in all_except_last:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 644,002\n",
      "Trainable params: 1,002\n",
      "Non-trainable params: 643,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 上一個cell 修改完屬性，所以這裡要重新把NN組合起來。 \n",
    "# Non-trainable params: 643,000 這裡是除了最後一層的之外的weight，因為剛剛設成untrainable\n",
    "model_eo.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_eo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 5,010\n",
      "Non-trainable params: 643,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_num.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_num.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 重新讀取**舊**模型權重 (並 evaluate)\n",
    "2. 定義新模型並凍結**舊**模型的部分 (set the layer that do not want to make change to 'untrainable' )\n",
    "3. 訓練新模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num.load_weights('handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 26us/step\n",
      "Loss: 0.470515\n",
      "準確率: 86.226666\n"
     ]
    }
   ],
   "source": [
    "score = model_num.evaluate(x_train, y_train, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1.1393 - acc: 0.5837\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4113 - acc: 0.8115\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3722 - acc: 0.8309\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3490 - acc: 0.8450\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3491 - acc: 0.8453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1da8bb470>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eo.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_eo.fit(x_train, y_train01, batch_size=1000, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 24us/step\n",
      "Loss: 0.470515\n",
      "準確率: 86.226666\n"
     ]
    }
   ],
   "source": [
    "score = model_num.evaluate(x_train, y_train, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 恭喜！現在的你/妳已經學會實作轉移學習了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然這個模型看起來很隨便，但轉移學習的模型**差不多**都是這樣建立的，實際上， Keras 亦提供許多被證實有良好表現且訓練好 (pre-trained) 的模型，如:\n",
    "\n",
    "* Xception\n",
    "* VGG16\n",
    "* VGG19\n",
    "* ResNet50\n",
    "* InceptionV3\n",
    "* InceptionResNetV2\n",
    "* MobileNet\n",
    "* DenseNet\n",
    "* NASNet\n",
    "\n",
    "詳細的使用方式可參考 Keras Documentation: https://keras.io/applications/\n",
    "\n",
    "但使用這些模型進行轉移學習，**可能**需要 ``Sequential`` 以外寫法，以及更多神經網路的建構技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 寫起來像寫數學函數的 Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之前，我們使用 Sequential 便足以建構大多數的神經網路，那是因為我們接觸的神經網路多為線性堆疊 (linear stack)。\n",
    "\n",
    "除了輸入層需指定 `input_dim` 外，其餘隱藏層只需宣告，那是因為 Sequential 會認定上一層的輸出這一層的輸入。\n",
    "\n",
    "因此，再建構線性堆疊的神經網路時，Sequential 便足以處理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Functional API 的使用時機"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當神經網路模型為非線性的複雜網路結構，如：\n",
    "\n",
    "* 多重輸出-多重輸入模型 (Multi-input and multi-output models) (watch youtube video)\n",
    "  + 分歧 (branch)\n",
    "  + 合併 (merge)\n",
    "* 具重複/循環結構的模型，如: CycleGAN\n",
    "\n",
    "Sequential 便不足以建構這類複雜結構的神經網路，我們以下介紹 `Model` Fnuctional API 的使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 `Model` 的世界中，所有的神經網路層 (全連接, 卷積, 池化, RNN等) 都將視作函數來定義，因此，我們只需關心函數的輸入和輸出即可。\n",
    "\n",
    "此外，為了讓神經網路的第一層從不需要輸入 `input_dim`，我們還需引進下面這個函數來代替 `input_dim`。 (此寫法亦可用在 `Sequential`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Functional API 的函數概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顧一下，我們想學習的手寫辨識模型是一個長得像這樣的函數\n",
    "\n",
    "$$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}^{10}$$\n",
    "\n",
    "我們希望建立一個具有兩個隱藏層的神經網路來學習這個函數，攤開來看的話，如下：\n",
    "\n",
    "$$\\mathbb{R}^{784} \\overset{f_1}{\\to} \\mathbb{R}^{500} \\overset{f_2}{\\to} \\mathbb{R}^{500} \\overset{f_3}{\\to} \\mathbb{R}^{10}$$\n",
    "\n",
    "$$x \\overset{f_1}{\\mapsto} h_1 \\overset{f_2}{\\mapsto} h_2 \\overset{f_3}{\\mapsto} y$$\n",
    "\n",
    "\n",
    "或是以簡易的圖來表示這個全連接神經網路\n",
    "\n",
    "<img src=\"plain_model.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "其中，$f_1, f_2, f_3$ 代表的是全連結層所代表的函數，其他變數說明如下：\n",
    "\n",
    "* $x$: 代表的是輸入模型的圖片向量，為 784 維的向量。\n",
    "* $h_1$: $x$ 經過第一層隱藏層運算後得結果，即為 $f_1(x)$，為 500 維的向量。\n",
    "* $h_2$: $h_1$ 經過第二層隱藏層運算後得結果，即為 $f_2(h_1)$，為 500 維的向量。\n",
    "* $y$: $h_2$ 經過最後一層運算後得結果，即為 $f_3(h_2)$，為 10 維的向量，代表的是 $x$ 為哪個數字的機率。\n",
    "\n",
    "注意: 為了方便，我們將 `Dense(500)`, `Activation('sigmoid')` 兩個合併用 `Dense(500, activation='sigmoid')` 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Functional API 的操作方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們沿用上圖的變數名稱來定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = Dense(500, activation='sigmoid') # the weight that from input layer(784) to the first hidden layer(500)\n",
    "f_2 = Dense(500, activation='sigmoid') # the weight that from first hidden layer(500) to the second hidden layer(500)\n",
    "f_3 = Dense(10, activation='softmax')  # the weight that from second hidden layer(500) to the output layer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x000001F1DB37ECF8>\n"
     ]
    }
   ],
   "source": [
    "print(f_1) # f1 is a object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，定義層前後變數之間的關係；首先，第一個變數必定以 `Input` 函數來定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剩下的部分，就如變數說明，**幾乎**可以照著數學式輸入 $$h_1 = f_1(x), h_2 = f_2(h_1), y = f_3(h_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1 = f_1(x)\n",
    "h_2 = f_2(h_1)\n",
    "y = f_3(h_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這裡，變數 $h_1, h_2, y$ 是以張量 (tensor) 類別來表示，我們可以嘗試 `print` 看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_17/Sigmoid:0\", shape=(?, 500), dtype=float32)\n",
      "Tensor(\"dense_18/Sigmoid:0\", shape=(?, 500), dtype=float32)\n",
      "Tensor(\"dense_19/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(h_1)\n",
    "print(h_2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，透過 `Model` 將一個模型的輸入/輸出包裝起來，建立模型的過程就完成了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# use 'Model' to pack the function we defined above.Only neeed to do is to specialize the input x and output y\n",
    "model = Model(x, y) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一樣的，當模型 compile 之後，便可以進行資料的訓練、預測等等，請有興趣的同學讀入 MNIST 手寫辨識之料後，自行完成這個模型的訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然 summary 少了很多東西，但模型架構和之前做的沒有差異，所以可以安心讀入之前訓練好的權重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 60us/step\n",
      "Loss: 0.021306\n",
      "準確率: 86.226666\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 小結論\n",
    "Functional API 的操作流程如下：\n",
    "1. 將層定義成明確的函數\n",
    "2. 透過層函數將變數連接\n",
    "3. 定義神經網路的輸入與輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 非線性堆疊模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 如果建立具分歧及合併結構的神經網路模型呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，假設我們希望在模型之間增加一個分歧，且這個分歧在模型的輸出會合併，則神經網路的結構會變成：\n",
    "\n",
    "<img src=\"branch-and-merge.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "此模型為單一輸入、多重輸出的模型，是分歧模型最容易處理的一種。\n",
    "\n",
    "其中，$f_1, f_2$ 同之前，$f_4:\\mathbb{R}^{500}\\to\\mathbb{R}^{500}$ 的全連接層，但 `Activation` 改用 `ReLu`。\n",
    "\n",
    "需注意的是，由於 $f_3$ 的定義域改變，為 $\\mathbb{R}^{500}\\times\\mathbb{R}^{500}\\to\\mathbb{R}^{10}$ 函數，所以需要重新定義。\n",
    "\n",
    "* $x$: 代表的是輸入模型的圖片向量，為 784 維的向量。\n",
    "* $h_1$: $x$ 經過 $f_1$ 隱藏層運算後得結果，即為 $f_1(x)$，為 500 維的向量。\n",
    "* $h_2$: $h_1$ 經過 $f_2$ 隱藏層運算後得結果，即為 $f_2(h_1)$，為 500 維的向量。\n",
    "\n",
    "* $z$: $h_1$ 經過 $f_4$ 運算後得結果，即為 $f_4(h_1)$，為 500 維的向量。\n",
    "* $y$: $h_2$ 和 $z$ 經過新的 $f_3$ 運算後得結果，即為 $f_3(h_1, z)$，為 10 維的向量，代表的是 $x$ 為哪個數字的機率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為上面已將 $f_4$ 及 $z$ 以外的變數定義好，我們只需定義 $f_3$, $f_4$ 及 $z$ 即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_4 = Dense(500, activation='relu')\n",
    "z = f_4(h_1)\n",
    "\n",
    "# new f_3\n",
    "f_3 = Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，再將 $y = f_3(h_1, z)$ 定義好，就會發現......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "y = f_3(h_2, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聰明的你/妳，可能會想到，函數的寫法是一次送進一個變數，那我們將 $h_3$ 和 $z$ 寫成 `list` 的形式，應該就可以送進去 $f_3$ 了吧？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "y = f_3([h_2, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "會發現這樣也沒辦法成功。其實正確的作法是，先將 $h_2$ 與 $z$ 透過 `concatenate` 接在一起，再送進新的 $f_3$ 裡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這裡，我們將 $h_2$ 與 $z$ `concatenate` 接在一起，稱做 $u$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = concatenate([h_2, z])\n",
    "y = f_3(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate_1/concat:0\", shape=(?, 1000), dtype=float32)\n",
      "Tensor(\"dense_21/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(u)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "換句話說，模型其實是這樣畫的\n",
    "\n",
    "<img src=\"branch-and-merge_final.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "其中，`concatenate` 是將不同的變數**接**在一起，這裡面並沒有進行任何涉及權重的運算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再透過 `Model` 將模型的輸入和輸出包裝起來，即可將模型建構完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 500)          392500      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 500)          250500      dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 500)          250500      dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000)         0           dense_18[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 10)           10010       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 903,510\n",
      "Trainable params: 903,510\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(x, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 小結論\n",
    "Branch-and-Merge 的注意要點如下：\n",
    "1. 每一層分別定義成函數\n",
    "2. 分歧結構: 實就是透過新的函數來定義新的變數，無特別注意事項。\n",
    "3. 合併結構: 要合併前，將所有要進入的變數都合併起來，才能進行之後的運算。\n",
    "\n",
    "常見應用:\n",
    "1. 多重輸入-多重輸出模型。\n",
    "2. 當層函數為 convolution 時，這樣的技巧可以實現 U-net 上的重要結構 multi-resolution fusion (多解析度融合，又稱 MRF)。\n",
    "3. ResNet 上的重要結構 skip connection (跳躍式傳遞)，亦可透過分歧-合併來實現，只是 ResNet 使用的是 `add` 而非 `concatenate`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 自定義的不具可訓練權重之神經網路層\n",
    "這裡，我們將進行這單元最後一個重要的神經網路建構技巧 - 自定義神經網路層 (不具可訓練權重)\n",
    "\n",
    "** 具有可訓練重的自定義層牽扯到 TensorFlow 及 Python 類別的撰寫，若有興趣可參考: https://keras.io/layers/writing-your-own-keras-layers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們需要引入 `Lambda` 這個函數，透過 `Lambda` 函數，我們可以將 Python 上的 function，包裝成 Keras 上的 layer。\n",
    "\n",
    "此外，我們需要引進後端所使用的套件 (此處為 TensorFlow)，並使用裡面的運算進行 function 的撰寫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們透過 backend 來定義一個簡單的 function，作用是對輸入取平均，程式碼如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_function(inputs):\n",
    "    return K.mean(inputs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們將一個 numpy array 送進這個函式，看看會發生什麼事。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "average_function(np.array([1, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你/妳會發現，這邊的函式不接受 numpy array 的類型作為輸入，這是因為 TensorFlow 有自定義的類型，因此，在這邊我們沒辦法直接使用這個函式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們透過 `Lambda` ，將上述函式包裝成一個神經網路層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_layer = Lambda(average_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Lambda object at 0x000001677AA2B898>\n"
     ]
    }
   ],
   "source": [
    "print(average_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此時，下述程式碼可以建構出一個將指定長度的資料取平均的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 4\n",
    "\n",
    "x = Input(shape=(inputSize,))\n",
    "y = average_layer(x)\n",
    "average_model = Model(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現，這樣的神經網路是不具有訓練權重的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None,)                   0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "average_model.summary() # note that we need to indicate the output dim. (none,) represent that NN won't output value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記得，在使用前記得先 compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們將 `[1, 2, 3, 4]` 送進這個神經網路，看看神經網路的輸出是否為這個向量的**平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2, 3, 4]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_model.predict(np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現，將 `[1, 2, 3, 4]` 轉成 Numpy array 送進神經網路**預測**後，答案是 `2.5`，即為 (1+2+3+4)/4，確實是平均。\n",
    "\n",
    "我們也可以一次送進多筆資料進行平均的計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5, 1. ], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_model.predict(np.array([[1, 2, 3, 4],\n",
    "                                [1, 1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加碼: 具抽樣功能的神經網路層\n",
    "\n",
    "輸入為 $(\\mu, s)$ ，$\\mu=(\\mu_1,\\cdots,\\mu_n)$ 和 $s=(s_1,\\cdots,s_n)$ 各自為 $n$ 維向量。\n",
    "\n",
    "我們希望神經網路層輸出為服從 $N(\\mu, e^{s}I_n)$ 的 $n$ 維向量，換言之，我們希望建構的神經網路其實是一個抽樣函數。\n",
    "\n",
    "** 由於神經網路的輸入輸出經常沒有限制，為了讓 $s$ 具有變異數的非負特性，我們考慮 $e^{s}$ 作為變異數；換言之，$s$ 為 log-variance。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假設我們想進行抽樣的維度為 `sampling_dim`，則一個具抽樣函數功能的神經網路可由下述方式建構。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dim = 2\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(sampling_dim,), mean=0., stddev=1)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡使用到常態分配的線性特性來定義函數，亦即\n",
    "\n",
    "$$X\\sim N(0, 1)\\Rightarrow \\mu+\\sigma X\\sim N(\\mu, \\sigma^2)$$\n",
    "\n",
    "\n",
    "若不熟機率論的同學，可以詢問助教。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_layer = Lambda(sampling, output_shape=(sampling_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Input(shape=(sampling_dim,))\n",
    "s = Input(shape=(sampling_dim,))\n",
    "\n",
    "z = sample_layer([m, s])\n",
    "\n",
    "sample_model = Model([m, s], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均為 (4, 7)\n"
     ]
    }
   ],
   "source": [
    "test_mean = np.random.randint(10, size=sampling_dim).reshape(1, 2)# must fit the input format of keres , so need to reshape it\n",
    "test_log_var = np.array([[0, 0]])\n",
    "\n",
    "print(\"平均為 (%d, %d)\" %(test_mean[0][0], test_mean[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過下面的指令，我們每次可以抽樣出一服從上述要求常態分配之隨機向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.572348 , 6.8892493]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model.predict([test_mean, test_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "來和 Numpy 上的抽樣函數進行比較吧~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_sample = np.random.multivariate_normal(test_mean[0], np.identity(2), size=num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "kears_sample = np.zeros((num_of_samples, 2))\n",
    "for i in range(num_of_samples):\n",
    "    kears_sample[i] = sample_model.predict([test_mean, test_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Normal Random Samples using Keras/Numpy')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1677aabebe0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(kears_sample[:, 0], kears_sample[:, 1], 'ro')\n",
    "plt.plot(np_sample[:, 0], np_sample[:, 1], 'o')\n",
    "plt.legend(['Keras', 'Numpy'])\n",
    "plt.title('Normal Random Samples using Keras/Numpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 恭喜你，完成所有建立 Variational Autoencoder 所需的重要技巧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoder (VAE) 是一個重要的非監督式學習模型，具體應用的場合為特徵抽取/資料壓縮及還原，為影像處理中常見的模型之一。\n",
    "\n",
    "在建立 VAE中，需要三個重要技巧:\n",
    "* 分歧-合併\n",
    "* 自定義函數 (抽樣函數)\n",
    "* 自定義損失函數\n",
    "\n",
    "雖然不知道之後課程會不會用到，但多學點總是好的 : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
