{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python_ML_DL Midterm Project\n",
    "\n",
    "\n",
    "## 題目: 從頭實作 Linear regression 和 logistic regression 並比較不同方法的正確率\n",
    "\n",
    "\n",
    "\n",
    "### 資料說明([資料來源](https://archive.ics.uci.edu/ml/datasets/Abalone))\n",
    "\n",
    "這個資料是紀錄鮑魚(abalone)的年齡與他們的重量、性別、直徑等等特徵的關係。會選這個資料除了因為data數量蠻多的(4177筆)，而且可以做linear regesssion 分析，也可以做logistic regression分析，符合我的需求。而且看起來也蠻有趣的，就選了這個dataset。\n",
    "\n",
    "### 功能\n",
    "\n",
    "**- Linear regression:**  我實作了3種不同的linear regression\n",
    "\n",
    "1-1: 直接呼叫 sklearn 的 LinearRegression <br>\n",
    "1-2: 自己實作Gradient descent 的 Linear regression，並討論收斂快慢的原因<br>\n",
    "1-3: 基於 Normal Equation 的 Linear regression <br>\n",
    "\n",
    "**- logistic regression**\n",
    "\n",
    "2-1: 自己實作 logistic regression => 因為有4個區間，所以需要套用4次model <br>\n",
    "2-2: 直接呼叫 sklearn 的 LogisticRegression => 呼叫一次函數就可以分類4個區間<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import locale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "#include自己寫的 function 進來\n",
    "%run ./LinearRegression.ipynb \n",
    "%run ./LogisticRegression.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、 Linear regression\n",
    "相關的 function 定義於 ./LinearRegression.ipynb 中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先讀進檔案並做preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight',\n",
      "       'Viscera weight', 'Shell weight', 'X0'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>X0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0    1   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1    1   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2    2   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3    1   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4    3   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera weight  Shell weight  X0  \n",
       "0          0.1010         0.150   1  \n",
       "1          0.0485         0.070   1  \n",
       "2          0.1415         0.210   1  \n",
       "3          0.1140         0.155   1  \n",
       "4          0.0395         0.055   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Replace(x):#把性別換成數字\n",
    "    if x.values=='M':\n",
    "        return 1\n",
    "    elif x.values == 'F':\n",
    "        return 2\n",
    "    elif x.values == 'I':\n",
    "        return 3\n",
    "\n",
    "dataset = pd.read_csv('./abalone.data',header=None)\n",
    "colnames = ['Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weight','Rings']\n",
    "dataset.columns = colnames \n",
    "#dataset.isnull().any() 檢查過沒有null了\n",
    "#dataset.shape =>(4177, 9)\n",
    "#把X 和 Y分離開( feature 和 result)\n",
    "Y= dataset.loc[:,['Rings']] \n",
    "X= dataset.drop(['Rings'],axis=1)\n",
    "X.loc[:,['Sex']] = X.loc[:,['Sex']].apply(Replace, axis=1)#把性別換成數字\n",
    "X['X0']=1 #我們通常會自己加入一行X0= 1，因為為了配合θ0*X0 + θ1*X1 + θ2*X2 中的θ0 ，θ0*1剛好就是θ0，因此要保持θ0是常數項就要讓X0=1。\n",
    "\n",
    "print(X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入多項式項次\n",
    "\n",
    "因為如此複雜的預測想必不是線性，所以要加入高次方項"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight',\n",
      "       'Viscera weight', 'Shell weight', 'X0', 'Sex2', 'Length2', 'Diameter2',\n",
      "       'Height2', 'Whole weight2', 'Shucked weight2', 'Viscera weight2',\n",
      "       'Shell weight2', 'Sex3', 'Length3', 'Diameter3', 'Height3',\n",
      "       'Whole weight3', 'Shucked weight3', 'Viscera weight3', 'Shell weight3',\n",
      "       'Sex4', 'Length4', 'Diameter4', 'Height4', 'Whole weight4',\n",
      "       'Shucked weight4', 'Viscera weight4', 'Shell weight4', 'Sex5',\n",
      "       'Length5', 'Diameter5', 'Height5', 'Whole weight5', 'Shucked weight5',\n",
      "       'Viscera weight5', 'Shell weight5', 'Sex6', 'Length6', 'Diameter6',\n",
      "       'Height6', 'Whole weight6', 'Shucked weight6', 'Viscera weight6',\n",
      "       'Shell weight6'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>X0</th>\n",
       "      <th>Sex2</th>\n",
       "      <th>...</th>\n",
       "      <th>Viscera weight5</th>\n",
       "      <th>Shell weight5</th>\n",
       "      <th>Sex6</th>\n",
       "      <th>Length6</th>\n",
       "      <th>Diameter6</th>\n",
       "      <th>Height6</th>\n",
       "      <th>Whole weight6</th>\n",
       "      <th>Shucked weight6</th>\n",
       "      <th>Viscera weight6</th>\n",
       "      <th>Shell weight6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051010e-05</td>\n",
       "      <td>7.593750e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>7.350919e-07</td>\n",
       "      <td>0.018441</td>\n",
       "      <td>1.280260e-04</td>\n",
       "      <td>1.061520e-06</td>\n",
       "      <td>1.139062e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.683544e-07</td>\n",
       "      <td>1.680700e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>5.314410e-07</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>9.703725e-07</td>\n",
       "      <td>1.301519e-08</td>\n",
       "      <td>1.176490e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.672601e-05</td>\n",
       "      <td>4.084101e-04</td>\n",
       "      <td>64</td>\n",
       "      <td>0.022164</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>6.053445e-06</td>\n",
       "      <td>0.096279</td>\n",
       "      <td>2.847897e-04</td>\n",
       "      <td>8.026730e-06</td>\n",
       "      <td>8.576612e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925415e-05</td>\n",
       "      <td>8.946610e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>3.814697e-06</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>1.001575e-04</td>\n",
       "      <td>2.194973e-06</td>\n",
       "      <td>1.386725e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>9.615801e-08</td>\n",
       "      <td>5.032844e-07</td>\n",
       "      <td>729</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>2.621440e-07</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>5.139705e-07</td>\n",
       "      <td>3.798241e-09</td>\n",
       "      <td>2.768064e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0    1   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1    1   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2    2   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3    1   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4    3   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera weight  Shell weight  X0  Sex2      ...        Viscera weight5  \\\n",
       "0          0.1010         0.150   1     1      ...           1.051010e-05   \n",
       "1          0.0485         0.070   1     1      ...           2.683544e-07   \n",
       "2          0.1415         0.210   1     4      ...           5.672601e-05   \n",
       "3          0.1140         0.155   1     1      ...           1.925415e-05   \n",
       "4          0.0395         0.055   1     9      ...           9.615801e-08   \n",
       "\n",
       "   Shell weight5  Sex6   Length6  Diameter6       Height6  Whole weight6  \\\n",
       "0   7.593750e-05     1  0.008873   0.002365  7.350919e-07       0.018441   \n",
       "1   1.680700e-06     1  0.001838   0.000346  5.314410e-07       0.000131   \n",
       "2   4.084101e-04    64  0.022164   0.005489  6.053445e-06       0.096279   \n",
       "3   8.946610e-05     1  0.007256   0.002365  3.814697e-06       0.018875   \n",
       "4   5.032844e-07   729  0.001291   0.000275  2.621440e-07       0.000074   \n",
       "\n",
       "   Shucked weight6  Viscera weight6  Shell weight6  \n",
       "0     1.280260e-04     1.061520e-06   1.139062e-05  \n",
       "1     9.703725e-07     1.301519e-08   1.176490e-07  \n",
       "2     2.847897e-04     8.026730e-06   8.576612e-05  \n",
       "3     1.001575e-04     2.194973e-06   1.386725e-05  \n",
       "4     5.139705e-07     3.798241e-09   2.768064e-08  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AddpolynomialFeature(X,6)#代表要加入1~6次方的所有feature，例如 Sex，就會有新column Sex2 Sex3...Sex6 表示1~6次方\n",
    "x_train,x_test,y_train,y_test =train_test_split(X,Y,test_size = 0.2, random_state = 4) #用80%做training set\n",
    "\n",
    "print(X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\">  1-1 : 直接呼叫 sklearn 的 LinearRegression </p>\n",
    "直接呼叫上課教到的 Library 測試結果 (function 定義於 ./LinearRegression.ipynb 中)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Library得到的R^2分數: 0.535627164320613\n"
     ]
    }
   ],
   "source": [
    "LinearR_CallFunc(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <p style=\"color:red;\"> 1-2 : Gradient-Descent linear regression </p>\n",
    "\n",
    "再來將自己實作基於 Gradient descent 的 Linear regression\n",
    "\n",
    "**Cost Function(或稱 Loss function)實作方法:**\n",
    "用 Square error 作為 loss function (用J(θ)表示) 。式子如下，其中$h_θ(x_i)$就是我們針對某組data $x^{(i)}$預測出的值，而$y^{(i)}$是這個data的正確值\n",
    "<br /><br />\n",
    "<font size=3> $J(θ) = \\frac{1}{2m} \\mathop{\\sum_{i=1}^{m}} (h_θ(x^{(i)})-y^{(i)})^2$ </font>\n",
    "\n",
    "\n",
    "**Gradient descent 實作方法:**<br /> \n",
    "<font size=3> $θ_j :=θ_j - α\\frac{\\partial}{\\partial θ_j} J(θ)$，代入上面的loss function J(θ) 後整理得到 $θ_j :=θ_j - \\frac{α}{m}\\mathop{\\sum_{i=1}^{m}} ( h_θ(x^{(i)})-y^{(i)} )x_{j}^{(i)}$</font>\n",
    "\n",
    "意思就是每輪更新我們要求的係數θ，而更新的方法就是利用 partial derivative 的方式，跟著坡度慢慢找到最小值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一開始的cost: 54.986830290332236\n"
     ]
    }
   ],
   "source": [
    "%run ./LinearRegression.ipynb\n",
    "θ = np.zeros((x_train.shape[1],1))# θ要和X的feature 一樣多，因為是θ0*X0+θ1*X1......由這個式子找出最佳的 θ 組合\n",
    "cost = CostFunction(θ,x_train.values,y_train.values)\n",
    "print('一開始的cost: '+str(cost)) #這裡只是先看看初始的cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**下面用Gradient descent實作可以發現，在學習率 α =0.000103， 迭代3000次仍然會讓cost只從55降到30左右，因此決定學習率是一件很重要的事，太大可能會無法收斂，太小又會發生下圖的現象，收斂十分的慢，而最後的score想必就十分的低，表示預測得很不準**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最後的cost: 29.21095340169312，發現這個gradient descent有underfitting問題，做得不是很好\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = 3000\n",
    "θ ,J= GradientDescent(x_train.values,y_train.values,θ,0.0000103,iterations)\n",
    "\n",
    "plotJ(J,iterations,100)\n",
    "\n",
    "#print(θ)\n",
    "print('最後的cost: '+str(J[iterations-1][0])+ '，發現這個gradient descent有underfitting問題，做得不是很好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2分數: -4.877755932578984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "predict = x_test.values @ θ\n",
    "\n",
    "print('R^2分數: '+str(r2_score(y_test.values,predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**為了解決我們上面收斂太慢的問題，我們可以用 Feature Scaling 的方式，把所有的 feature normalize 成相近的值，收斂就會比較快。 並調大learning rate。下圖就可以注意到我們只用了1500次迭代就使函數收斂(其實200次以後就變動很小了)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終 Gradient Descent 法 R^2分數: 0.5197200526969354\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############這裡在做Normalize#########################\n",
    "stored_feature_means, stored_feature_stds = [], []\n",
    "Xnorm = X.copy()\n",
    "Xnorm.shape[1]\n",
    "\n",
    "for icol in range(Xnorm.shape[1]):\n",
    "    stored_feature_means.append(np.mean(Xnorm.iloc[:,icol]))\n",
    "    stored_feature_stds.append(np.std(Xnorm.iloc[:,icol]))\n",
    "    Xnorm.iloc[:,icol] = (Xnorm.iloc[:,icol] - stored_feature_means[-1])/stored_feature_stds[-1]\n",
    "\n",
    "Xnorm.loc[:,'X0']=1\n",
    "######################################################\n",
    "\n",
    "xnorm_train,xnorm_test,ynorm_train,ynorm_test =train_test_split(Xnorm,Y,test_size = 0.2, random_state = 4) #用80%做training set\n",
    "\n",
    "θ = np.zeros((Xnorm.shape[1],1))# θ要和X的feature 一樣多，因為是θ0*X0+θ1*X1......由這個式子找出最佳的 θ 組合\n",
    "###########\n",
    "iterations = 1500\n",
    "θ ,J= GradientDescent(xnorm_train.values,ynorm_train.values,θ,0.07,iterations)\n",
    "plotJ(J,iterations,1)\n",
    "predict2 = xnorm_test.values @ θ\n",
    "print('最終 Gradient Descent 法 R^2分數: '+str(r2_score(y_test.values,predict2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\"> 1-3 : Normal Equation </p>\n",
    "\n",
    "$θ = (X^T X)^{-1} X^T y$\n",
    "\n",
    "這種方法是直接找多項式的通解，用數學一步解出最精準的答案。但缺點就是 feature 一多，將會比gradient descent 計算慢得多，因為矩陣乘法會很慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終 normal equation 法 R^2分數: 0.5178770606850983\n"
     ]
    }
   ],
   "source": [
    "%run ./LinearRegression.ipynb\n",
    "\n",
    "θ_normalEq = np.zeros((Xnorm.shape[1],1))\n",
    "θ_normalEq = NormalEqn(xnorm_train.values,ynorm_train.values)\n",
    "θ_normalEq\n",
    "predict_normalEq = xnorm_test.values @ θ_normalEq\n",
    "r2_score(y_test.values,predict_normalEq)\n",
    "print('最終 normal equation 法 R^2分數: '+str(r2_score(y_test.values,predict_normalEq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\"> Linear regression 結論 </p>\n",
    "\n",
    "我們發現呼叫 1-1 直接呼叫 sklearn 的 LinearRegression 的分數是 **0.535**， 1-2 Gradient Descent 法分數是 **0.519** ，1-3 normal equation 法 分數是 **0.517**。<br />\n",
    "\n",
    "三者其實相差無幾，但 sklearn 的 LinearRegression 高了一點點，因此可能是其中用的一些方法與這裡不同。但1-2和1-3的 Model 其實還可以透過regularization 的方式，以減少可能 overfitting 的可能，讓最後的表現再提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、 logistic regression\n",
    "相關的 function 定義於 ./LogisticRegression.ipynb 中\n",
    "\n",
    "因為上面的Linear regression 分數只有0.54，其實好像還有進步空間，所以我們用 classification 的 model 試試看會不會表現比較好。\n",
    "這裡要重新 label 數據的 output。我是分成4個區間，0~5、6~10、11~15、16以上。 (因為data大約是0~20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\"> 2-1 : 用 optimize.fmin </p>\n",
    "\n",
    "第一種作法是我從頭實作的，其中的觀念如下:\n",
    "\n",
    "logistic regression本來是用來分0和1的(就是classification model)，而其 hypothesis function 的 output 意義為是這個label的機率為何。因此我們如果要判斷是4個中的哪個區間，只要套用 4 個 logistic regression ，就能知道區間1 2 3 4的機率各為何，我們再從其中選出機率最高的，就是我們的答案了。\n",
    "\n",
    "而這裡求出每個 logistic regression 我是直接呼叫 optimize.fmin ，這個函數可以直接找到 optima ，這個部分也可以用gradient descent法來做。\n",
    "optimize.fmin有一個 argument 要填 'maxiter=XXX' 也就是這個函數最多能迭代幾次找到最佳解，若是超過了找不到就先停下來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "%run ./LogisticRegression.ipynb #include這個file進來\n",
    "from scipy import optimize\n",
    "def optimizeTheta(mytheta,myX,myy,mylambda=0.):\n",
    "    result = optimize.fmin(CostFunction_Logi, x0=mytheta, args=(myX, myy), maxiter=3000, full_output=True)\n",
    "    return result[0], result[1]\n",
    "\n",
    "\n",
    "X_logi= Xnorm.copy()\n",
    "Y_logi= Y.copy()\n",
    "Y_logi.loc[:,'Rings']= Y_logi.loc[:,'Rings'].apply(classification)#將年齡分成4種 分別為 1 2 3 4\n",
    "\n",
    "θ_1 = np.zeros((X_logi.shape[1],1))\n",
    "θ_2 = np.zeros((X_logi.shape[1],1))\n",
    "θ_3 = np.zeros((X_logi.shape[1],1))\n",
    "θ_4 = np.zeros((X_logi.shape[1],1))\n",
    "\n",
    "Y_1= Y_logi.loc[:,'Rings'].apply(Now_classify,who = 1).to_frame()\n",
    "Y_2= Y_logi.loc[:,'Rings'].apply(Now_classify,who = 2).to_frame()\n",
    "Y_3= Y_logi.loc[:,'Rings'].apply(Now_classify,who = 3).to_frame()\n",
    "Y_4= Y_logi.loc[:,'Rings'].apply(Now_classify,who = 4).to_frame()\n",
    "\n",
    "### TODO:  Y_1 Y_2 Y_3 Y_4都需要做一次(因為classification) 最後需要把所有的放進predict中去看max 是那個index，那個index就是最後結果\n",
    "X_logi_train1,X_logi_test1,Y_logi_train1,Y_logi_test1 = \\\n",
    "train_test_split(X_logi,Y_1,test_size = 0.2, random_state = 2) #用80%做training set\n",
    "\n",
    "X_logi_train2,X_logi_test2,Y_logi_train2,Y_logi_test2 = \\\n",
    "train_test_split(X_logi,Y_2,test_size = 0.2, random_state = 2) #用80%做training set\n",
    "\n",
    "X_logi_train3,X_logi_test3,Y_logi_train3,Y_logi_test3 = \\\n",
    "train_test_split(X_logi,Y_3,test_size = 0.2, random_state = 2) #用80%做training set\n",
    "\n",
    "X_logi_train4,X_logi_test4,Y_logi_train4,Y_logi_test4 = \\\n",
    "train_test_split(X_logi,Y_4,test_size = 0.2, random_state = 2) #用80%做training set\n",
    "\n",
    "\n",
    "\n",
    "#print(Y_logi_test)\n",
    "#CostFunction_Logi(θ,X_logi.values,Y_logi.values)\n",
    "theta1, mincost1 = optimizeTheta(θ_1,X_logi_train1.values,Y_logi_train1.values)\n",
    "theta2, mincost2 = optimizeTheta(θ_2,X_logi_train2.values,Y_logi_train2.values)\n",
    "theta3, mincost3 = optimizeTheta(θ_3,X_logi_train3.values,Y_logi_train3.values)\n",
    "theta4, mincost4 = optimizeTheta(θ_4,X_logi_train4.values,Y_logi_train4.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 個 testing data 中有 316 個 data 預測失誤 正確率 62.20095693779904 %\n"
     ]
    }
   ],
   "source": [
    "#4個區間分別的機率是多少\n",
    "predict1 = Sigmoid(X_logi_test1 @ theta1)\n",
    "predict2 = Sigmoid(X_logi_test2 @ theta2)\n",
    "predict3 = Sigmoid(X_logi_test3 @ theta3)\n",
    "predict4 = Sigmoid(X_logi_test4 @ theta4)\n",
    "\n",
    "'''\n",
    "Test = predict.copy()\n",
    "Test = pd.concat([Y_1,Y_2,Y_3,Y_4], axis=1)\n",
    "#Result.append(predict)\n",
    "'''\n",
    "#predict.index\n",
    "Result = pd.concat([predict1,predict2,predict3,predict4], axis=1)\n",
    "Result\n",
    "#=========================================\n",
    "#這裡的方法就是，我們上面已經求出了4個區間分別的機率，因此這裡只要取max就知道是哪個區間機率最大。(+1是因為index從0開始，而我的區間編號從1)\n",
    "Result.idxmax(axis = 1)+1\n",
    "#=========================================\n",
    "count = 0\n",
    "right = 0\n",
    "for i in Result.index :\n",
    "    #print(Result.loc[i,:].idxmax(axis = 1)+1)\n",
    "    #print(Y_logi.loc[i,'Rings'])\n",
    "    #算正確的有幾個\n",
    "    if((Result.loc[i,:].idxmax(axis = 1)+1)==(Y_logi.loc[i,'Rings'])):\n",
    "        right=right+1\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{Y_logi_test1.size} 個 testing data 中有 {Y_logi_test1.size-right} 個 data 預測失誤 正確率 {100 *right/Y_logi_test1.size} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\"> 2-2 : 直接呼叫function </p>\n",
    "\n",
    "呼叫 logistic function 就親民多了，可以進到我的 LogisticR_CallFunc 裡面看，只要宣告 model 為 logistic regression 就可以，不用像上面一樣套用4個 logistic regression model。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 個 testing data 中有 285 個 data 預測失誤 正確率 65.9090909090909 %\n"
     ]
    }
   ],
   "source": [
    "X_logi_train,X_logi_test,Y_logi_train,Y_logi_test = \\\n",
    "train_test_split(X_logi,Y_logi,test_size = 0.2, random_state = 2) #用80%做training set\n",
    "\n",
    "LogisticR_CallFunc(X_logi_train,X_logi_test,Y_logi_train,Y_logi_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\"> Linear regression 結論 </p>\n",
    "\n",
    "發現自己實作的正確率是**62%**左右，而直接呼叫 library 正確率是**65%**左右。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
